{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Upload data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import glob\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***JSON files***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "url_jan = \"../data/raw/json/202201.json\"\n",
                "jan_22_json = pd.read_json(url_jan, lines=True)\n",
                "\n",
                "url_feb = \"../data/raw/json/202202.json\"\n",
                "feb_22_json = pd.read_json(url_feb, lines=True)\n",
                "\n",
                "url_mar = \"../data/raw/json/202203.json\"\n",
                "mar_22_json = pd.read_json(url_mar, lines=True)\n",
                "\n",
                "url_apr = \"../data/raw/json/202204.json\"\n",
                "apr_22_json = pd.read_json(url_apr, lines=True)\n",
                "\n",
                "url_may = \"../data/raw/json/202205.json\"\n",
                "may_22_json = pd.read_json(url_may, lines=True)\n",
                "\n",
                "url_jun = \"../data/raw/json/202206.json\"\n",
                "jun_22_json = pd.read_json(url_jun, lines=True)\n",
                "\n",
                "url_jul = \"../data/raw/json/202207.json\"\n",
                "jul_22_json = pd.read_json(url_jul, lines=True)\n",
                "\n",
                "url_aug = \"../data/raw/json/202208.json\"\n",
                "aug_22_json = pd.read_json(url_aug, lines=True)\n",
                "\n",
                "url_sep = \"../data/raw/json/202209.json\"\n",
                "sep_22_json = pd.read_json(url_sep, lines=True)\n",
                "\n",
                "url_oct = \"../data/raw/json/202210.json\"\n",
                "oct_22_json = pd.read_json(url_oct, lines=True)\n",
                "\n",
                "url_nov = \"../data/raw/json/202211.json\"\n",
                "nov_22_json = pd.read_json(url_nov, lines=True)\n",
                "\n",
                "url_dec = \"../data/raw/json/202212.json\"\n",
                "dec_22_json = pd.read_json(url_dec, lines=True)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-Combined-"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "file_json_list = glob.glob(\"../data/raw/json/*.json\")\n",
                "\n",
                "# Create an empty list to store the DataFrames\n",
                "data_frames = []\n",
                "\n",
                "# Read each JSON file into a DataFrame and append it to the list\n",
                "for file in file_json_list:\n",
                "    data_frame = pd.read_json(file, lines=True)  \n",
                "    data_frames.append(data_frame)\n",
                "\n",
                "# Concatenate all DataFrames into one\n",
                "combined_df = pd.concat(data_frames, ignore_index=True)\n",
                "\n",
                "# Save the combined DataFrame to a new JSON file\n",
                "combined_df.to_json('combined_json.json', orient='records', lines=True)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***CSV files***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "url_jan_csv = \"../data/raw/csv/trips_22_01_January.csv\"\n",
                "jan_22_csv = pd.read_csv(url_jan_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_feb_csv = \"../data/raw/csv/trips_22_02_February.csv\"\n",
                "feb_22_csv = pd.read_csv(url_feb_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_mar_csv = \"../data/raw/csv/trips_22_03_March.csv\"\n",
                "mar_22_csv = pd.read_csv(url_mar_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_apr_csv = \"../data/raw/csv/trips_22_04_April.csv\"\n",
                "apr_22_csv = pd.read_csv(url_apr_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_may_csv = \"../data/raw/csv/trips_22_05_May.csv\"\n",
                "may_22_csv = pd.read_csv(url_may_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_jun_csv = \"../data/raw/csv/trips_22_06_June.csv\"\n",
                "jun_22_csv = pd.read_csv(url_jun_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_jul_csv = \"../data/raw/csv/trips_22_07_July.csv\"\n",
                "jul_22_csv = pd.read_csv(url_jul_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_aug_csv = \"../data/raw/csv/trips_22_08_August.csv\"\n",
                "aug_22_csv = pd.read_csv(url_aug_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_sep_csv = \"../data/raw/csv/trips_22_09_September.csv\"\n",
                "sep_22_csv = pd.read_csv(url_sep_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_oct_csv = \"../data/raw/csv/trips_22_10_October.csv\"\n",
                "oct_22_csv = pd.read_csv(url_oct_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_nov_csv = \"../data/raw/csv/trips_22_11_November.csv\"\n",
                "nov_22_csv = pd.read_csv(url_nov_csv, sep=';', low_memory=False)\n",
                "\n",
                "url_dec_csv = \"../data/raw/csv/trips_22_12_December.csv\"\n",
                "dec_22_csv = pd.read_csv(url_dec_csv, sep=';', low_memory=False)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Set low_memory=False: This parameter is used to disable automatic data type detection for large columns. To set it we use low_memory=False when reading the file."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-Combined-"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "file_csv_list = glob.glob(\"../data/raw/csv/*.csv\")\n",
                "\n",
                "# Create an empty list to store the DataFrames\n",
                "data_frames_csv = []\n",
                "\n",
                "# Read each CSV file into a DataFrame and append it to the list\n",
                "for file in file_csv_list:\n",
                "    data_frame_csv = pd.read_csv(file, sep=';', low_memory=False)  # Appying low_memory=False\n",
                "    data_frames_csv.append(data_frame_csv)\n",
                "\n",
                "# Concatenate all DataFrames into one\n",
                "combined_df_csv = pd.concat(data_frames_csv, ignore_index=True)\n",
                "\n",
                "# Save the combined DataFrame to a new CSV file\n",
                "combined_df_csv.to_csv('combined_csv.csv', index=False)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
