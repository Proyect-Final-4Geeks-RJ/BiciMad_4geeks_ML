{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Clean Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Import libraries***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import datetime\n",
                "import ast\n",
                "import warnings\n",
                "import numpy as np\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### CSV FILE ###"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Read data file***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data = pd.read_csv(\"../data/raw/csv/combined_csv.csv\", sep=\",\", low_memory=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Delete the null rows***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.dropna(how=\"all\", inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Modify column contents***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Fecha"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.rename(columns={'fecha': 'unlock_date1'}, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* idTrip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['idTrip'] = trips_data['idTrip'].fillna(trips_data['idTrip']).str.slice(stop=9)\n",
                "trips_data.rename(columns={'idTrip': 'idDriver'}, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* IdBike"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['idBike'] = trips_data['idBike'].astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Fleet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['fleet'] = trips_data['fleet'].astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Geolocation_unlock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['geolocation_unlock'] = trips_data['geolocation_unlock'].apply(ast.literal_eval)\n",
                "trips_data['latitude_unlock'] = trips_data['geolocation_unlock'].apply(lambda x: x['coordinates'][1])\n",
                "trips_data['longitude_unlock'] = trips_data['geolocation_unlock'].apply(lambda x: x['coordinates'][0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['latitude_unlock'] = trips_data['latitude_unlock'].astype(str).str.slice(stop=8)\n",
                "trips_data['longitude_unlock'] = trips_data['longitude_unlock'].astype(str).str.slice(stop=8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.drop(['geolocation_unlock'], axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Unlock_date"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['unlock_date'] = trips_data['unlock_date'].str.split('T').str[-1]\n",
                "trips_data.rename(columns={'unlock_date': 'unlock_hour'}, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.rename(columns={'unlock_date1': 'unlock_date'}, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Geolocation_lock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['geolocation_lock'] = trips_data['geolocation_lock'].apply(ast.literal_eval)\n",
                "trips_data['latitude_lock'] = trips_data['geolocation_lock'].apply(lambda x: x['coordinates'][1])\n",
                "trips_data['longitude_lock'] = trips_data['geolocation_lock'].apply(lambda x: x['coordinates'][0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['latitude_lock'] = trips_data['latitude_lock'].astype(str).str.slice(stop=8)\n",
                "trips_data['longitude_lock'] = trips_data['longitude_lock'].astype(str).str.slice(stop=8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.drop(['geolocation_lock'], axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Lock_date"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['lock_date'] = pd.to_datetime(trips_data['lock_date'])\n",
                "trips_data['lock_date1'] = trips_data['lock_date'].dt.date\n",
                "trips_data['lock_hour'] = trips_data['lock_date'].dt.time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.drop(['lock_date'], axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.rename(columns={'lock_date1': 'lock_date'}, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Station_unlock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['station_unlock'] = pd.to_numeric(trips_data['station_unlock'], errors='coerce')\n",
                "trips_data['station_unlock'] = trips_data['station_unlock'].fillna(0).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Dock_unlock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['dock_unlock'] = pd.to_numeric(trips_data['dock_unlock'], errors='coerce')\n",
                "trips_data['dock_unlock'] = trips_data['dock_unlock'].fillna(0).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Station_lock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['station_lock'] = pd.to_numeric(trips_data['station_lock'], errors='coerce')\n",
                "trips_data['station_lock'] = trips_data['station_lock'].fillna(0).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* Dock_lock"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['dock_lock'] = pd.to_numeric(trips_data['dock_lock'], errors='coerce')\n",
                "trips_data['dock_lock'] = trips_data['dock_lock'].fillna(0).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Sort the columns***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.head().T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data = trips_data.reindex(columns=['idDriver', 'idBike', 'trip_minutes', 'fleet', 'unlock_date', 'unlock_hour', 'latitude_unlock', 'longitude_unlock', 'address_unlock', 'unlocktype', 'station_unlock', 'dock_unlock', 'unlock_station_name','lock_date', 'lock_hour', 'latitude_lock', 'longitude_lock', 'address_lock', 'locktype', 'station_lock', 'dock_lock', 'lock_station_name'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Save the clean file***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data.to_csv('../data/processed/clean_data_trips.csv', index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### JSON FILE ###"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Read data file***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations = pd.read_json(r'C:\\Users\\jlizo\\Desktop\\BiciMad_4geeks_ML\\data\\processed\\combined_json.json', lines=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Concat the columns***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "stations_df = pd.json_normalize(data_stations['stations'].explode()) # To normalize json by 'stations'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "replicas = 264 # Pre-calculate with dataset of 'trips' by concat the same values\n",
                "data_stations_rep = pd.concat([data_stations]*replicas)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations_rep = data_stations_rep.reset_index(drop=True) # Reset index for cleaning dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "stations_data = pd.concat([data_stations_rep, stations_df], axis=1, join='outer') # To finish the concatened information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>_id</th>\n",
                            "      <th>stations</th>\n",
                            "      <th>activate</th>\n",
                            "      <th>name</th>\n",
                            "      <th>reservations_count</th>\n",
                            "      <th>light</th>\n",
                            "      <th>total_bases</th>\n",
                            "      <th>free_bases</th>\n",
                            "      <th>number</th>\n",
                            "      <th>longitude</th>\n",
                            "      <th>no_available</th>\n",
                            "      <th>address</th>\n",
                            "      <th>latitude</th>\n",
                            "      <th>dock_bikes</th>\n",
                            "      <th>id</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>2022-01-01T00:13:20.603583</td>\n",
                            "      <td>[{'activate': 1, 'name': 'Puerta del Sol A', '...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Puerta del Sol A</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1a</td>\n",
                            "      <td>-3.7018341</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Puerta del Sol nº 1</td>\n",
                            "      <td>40.4172137</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>2022-01-01T01:13:21.911079</td>\n",
                            "      <td>[{'activate': 1, 'name': 'Puerta del Sol A', '...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Puerta del Sol B</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1b</td>\n",
                            "      <td>-3.701602938060457</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Puerta del Sol nº 1</td>\n",
                            "      <td>40.41731271011562</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>2022-01-01T02:13:23.718951</td>\n",
                            "      <td>[{'activate': 1, 'name': 'Puerta del Sol A', '...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Miguel Moya</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>24</td>\n",
                            "      <td>16</td>\n",
                            "      <td>2</td>\n",
                            "      <td>-3.7058415</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Calle Miguel Moya nº 1</td>\n",
                            "      <td>40.4205886</td>\n",
                            "      <td>7</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>2022-01-01T03:13:23.902654</td>\n",
                            "      <td>[{'activate': 1, 'name': 'Puerta del Sol A', '...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Plaza Conde Suchil</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>18</td>\n",
                            "      <td>1</td>\n",
                            "      <td>3</td>\n",
                            "      <td>-3.7069171</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Plaza del Conde del Valle de Súchil nº 3</td>\n",
                            "      <td>40.4302937</td>\n",
                            "      <td>14</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>2022-01-01T04:13:26.826536</td>\n",
                            "      <td>[{'activate': 1, 'name': 'Puerta del Sol A', '...</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Malasaña</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>24</td>\n",
                            "      <td>2</td>\n",
                            "      <td>4</td>\n",
                            "      <td>-3.7025875</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Calle Manuela Malasaña nº 5</td>\n",
                            "      <td>40.4285524</td>\n",
                            "      <td>17</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                          _id  \\\n",
                            "0  2022-01-01T00:13:20.603583   \n",
                            "1  2022-01-01T01:13:21.911079   \n",
                            "2  2022-01-01T02:13:23.718951   \n",
                            "3  2022-01-01T03:13:23.902654   \n",
                            "4  2022-01-01T04:13:26.826536   \n",
                            "\n",
                            "                                            stations  activate  \\\n",
                            "0  [{'activate': 1, 'name': 'Puerta del Sol A', '...         1   \n",
                            "1  [{'activate': 1, 'name': 'Puerta del Sol A', '...         1   \n",
                            "2  [{'activate': 1, 'name': 'Puerta del Sol A', '...         1   \n",
                            "3  [{'activate': 1, 'name': 'Puerta del Sol A', '...         1   \n",
                            "4  [{'activate': 1, 'name': 'Puerta del Sol A', '...         1   \n",
                            "\n",
                            "                 name  reservations_count  light  total_bases  free_bases  \\\n",
                            "0    Puerta del Sol A                   0      3           30           0   \n",
                            "1    Puerta del Sol B                   0      3           30           0   \n",
                            "2         Miguel Moya                   0      0           24          16   \n",
                            "3  Plaza Conde Suchil                   0      1           18           1   \n",
                            "4            Malasaña                   0      1           24           2   \n",
                            "\n",
                            "  number           longitude  no_available  \\\n",
                            "0     1a          -3.7018341             1   \n",
                            "1     1b  -3.701602938060457             1   \n",
                            "2      2          -3.7058415             0   \n",
                            "3      3          -3.7069171             0   \n",
                            "4      4          -3.7025875             0   \n",
                            "\n",
                            "                                    address           latitude  dock_bikes  id  \n",
                            "0                       Puerta del Sol nº 1         40.4172137           0   1  \n",
                            "1                       Puerta del Sol nº 1  40.41731271011562           0   2  \n",
                            "2                    Calle Miguel Moya nº 1         40.4205886           7   3  \n",
                            "3  Plaza del Conde del Valle de Súchil nº 3         40.4302937          14   4  \n",
                            "4               Calle Manuela Malasaña nº 5         40.4285524          17   5  "
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "stations_data.head() # Read the head data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Modify the columns**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### COMENTAR"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* _id:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "stations_data['_id'] = pd.to_datetime(stations_data['_id'])\n",
                "stations_data['date_station'] = stations_data['_id'].dt.date\n",
                "stations_data['hour_station'] = stations_data['_id'].dt.time"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "stations_data['_id'] = stations_data['_id'].astype(str)\n",
                "stations_data['_id'] = stations_data['_id'].str.slice(-6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* hour_station"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "stations_data['hour_station'] = stations_data['hour_station'].astype(str)\n",
                "stations_data['hour_station'] = stations_data['hour_station'].str.slice(stop=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* longitude & latitude"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "stations_data['longitude'] = stations_data['longitude'].str.slice(stop=8)\n",
                "stations_data['latitude'] = stations_data['latitude'].str.slice(stop=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Select the neccessary columns for lock and unlock stations***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations_final_unlock = stations_data[['name', 'number','date_station', 'hour_station', 'longitude', 'latitude', 'light', 'total_bases', 'free_bases', 'no_available', 'dock_bikes']]\n",
                "data_stations_final_unlock.rename(columns={'date_station': 'unlock_date', 'hour_station': 'unlock_hour', 'longitude': 'longitude_unlock', 'latitude': 'latitude_unlock', 'name':  'name_unlock', 'number': 'number_unlock','light' : 'light_unlock', 'total_bases' : 'total_bases_unlock', 'free_bases' : 'free_bases_unlock', 'no_available' : 'no_available_unlock', 'dock_bikes' : 'dock_bikes_unlock'}, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations_final_lock = stations_data[['name', 'number','date_station', 'hour_station', 'longitude', 'latitude', 'light', 'total_bases', 'free_bases', 'no_available', 'dock_bikes']]\n",
                "data_stations_final_lock.rename(columns={'date_station': 'lock_date', 'hour_station': 'lock_hour', 'longitude': 'longitude_lock', 'latitude': 'latitude_lock', 'name':  'name_lock', 'number': 'number_lock', 'light' : 'light_lock', 'total_bases' : 'total_bases_lock', 'free_bases' : 'free_bases_lock', 'no_available' : 'no_available_lock', 'dock_bikes' : 'dock_bikes_lock'}, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Concat the datasets***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations_final_unlock_lock = pd.concat([data_stations_final_unlock, data_stations_final_lock], axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Save the dataset***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations_final_unlock_lock.to_csv(r'C:\\Users\\jlizo\\Desktop\\BiciMad_4geeks_ML\\data\\processed\\clean_data_stations.csv', index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Read and visualize the clenaed dataset***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_stations_clean_inferences = pd.read_csv(r'C:\\Users\\jlizo\\Desktop\\BiciMad_4geeks_ML\\data\\processed\\clean_data_stations.csv', sep=',')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>name_unlock</th>\n",
                            "      <th>number_unlock</th>\n",
                            "      <th>unlock_date</th>\n",
                            "      <th>unlock_hour</th>\n",
                            "      <th>longitude_unlock</th>\n",
                            "      <th>latitude_unlock</th>\n",
                            "      <th>light_unlock</th>\n",
                            "      <th>total_bases_unlock</th>\n",
                            "      <th>free_bases_unlock</th>\n",
                            "      <th>no_available_unlock</th>\n",
                            "      <th>...</th>\n",
                            "      <th>number_lock</th>\n",
                            "      <th>lock_date</th>\n",
                            "      <th>lock_hour</th>\n",
                            "      <th>longitude_lock</th>\n",
                            "      <th>latitude_lock</th>\n",
                            "      <th>light_lock</th>\n",
                            "      <th>total_bases_lock</th>\n",
                            "      <th>free_bases_lock</th>\n",
                            "      <th>no_available_lock</th>\n",
                            "      <th>dock_bikes_lock</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Puerta del Sol A</td>\n",
                            "      <td>1a</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>00:13:20</td>\n",
                            "      <td>-3.70183</td>\n",
                            "      <td>40.41721</td>\n",
                            "      <td>3</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1a</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>00:13:20</td>\n",
                            "      <td>-3.70183</td>\n",
                            "      <td>40.41721</td>\n",
                            "      <td>3</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>Puerta del Sol B</td>\n",
                            "      <td>1b</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>01:13:21</td>\n",
                            "      <td>-3.70160</td>\n",
                            "      <td>40.41731</td>\n",
                            "      <td>3</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1b</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>01:13:21</td>\n",
                            "      <td>-3.70160</td>\n",
                            "      <td>40.41731</td>\n",
                            "      <td>3</td>\n",
                            "      <td>30</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Miguel Moya</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>02:13:23</td>\n",
                            "      <td>-3.70584</td>\n",
                            "      <td>40.42058</td>\n",
                            "      <td>0</td>\n",
                            "      <td>24</td>\n",
                            "      <td>16</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>02:13:23</td>\n",
                            "      <td>-3.70584</td>\n",
                            "      <td>40.42058</td>\n",
                            "      <td>0</td>\n",
                            "      <td>24</td>\n",
                            "      <td>16</td>\n",
                            "      <td>0</td>\n",
                            "      <td>7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Plaza Conde Suchil</td>\n",
                            "      <td>3</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>03:13:23</td>\n",
                            "      <td>-3.70691</td>\n",
                            "      <td>40.43029</td>\n",
                            "      <td>1</td>\n",
                            "      <td>18</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>3</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>03:13:23</td>\n",
                            "      <td>-3.70691</td>\n",
                            "      <td>40.43029</td>\n",
                            "      <td>1</td>\n",
                            "      <td>18</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>14</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Malasaña</td>\n",
                            "      <td>4</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>04:13:26</td>\n",
                            "      <td>-3.70258</td>\n",
                            "      <td>40.42855</td>\n",
                            "      <td>1</td>\n",
                            "      <td>24</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>4</td>\n",
                            "      <td>2022-01-01</td>\n",
                            "      <td>04:13:26</td>\n",
                            "      <td>-3.70258</td>\n",
                            "      <td>40.42855</td>\n",
                            "      <td>1</td>\n",
                            "      <td>24</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>17</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 22 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          name_unlock number_unlock unlock_date unlock_hour  longitude_unlock  \\\n",
                            "0    Puerta del Sol A            1a  2022-01-01    00:13:20          -3.70183   \n",
                            "1    Puerta del Sol B            1b  2022-01-01    01:13:21          -3.70160   \n",
                            "2         Miguel Moya             2  2022-01-01    02:13:23          -3.70584   \n",
                            "3  Plaza Conde Suchil             3  2022-01-01    03:13:23          -3.70691   \n",
                            "4            Malasaña             4  2022-01-01    04:13:26          -3.70258   \n",
                            "\n",
                            "   latitude_unlock  light_unlock  total_bases_unlock  free_bases_unlock  \\\n",
                            "0         40.41721             3                  30                  0   \n",
                            "1         40.41731             3                  30                  0   \n",
                            "2         40.42058             0                  24                 16   \n",
                            "3         40.43029             1                  18                  1   \n",
                            "4         40.42855             1                  24                  2   \n",
                            "\n",
                            "   no_available_unlock  ...  number_lock   lock_date lock_hour longitude_lock  \\\n",
                            "0                    1  ...           1a  2022-01-01  00:13:20       -3.70183   \n",
                            "1                    1  ...           1b  2022-01-01  01:13:21       -3.70160   \n",
                            "2                    0  ...            2  2022-01-01  02:13:23       -3.70584   \n",
                            "3                    0  ...            3  2022-01-01  03:13:23       -3.70691   \n",
                            "4                    0  ...            4  2022-01-01  04:13:26       -3.70258   \n",
                            "\n",
                            "  latitude_lock  light_lock  total_bases_lock  free_bases_lock  \\\n",
                            "0      40.41721           3                30                0   \n",
                            "1      40.41731           3                30                0   \n",
                            "2      40.42058           0                24               16   \n",
                            "3      40.43029           1                18                1   \n",
                            "4      40.42855           1                24                2   \n",
                            "\n",
                            "   no_available_lock  dock_bikes_lock  \n",
                            "0                  1                0  \n",
                            "1                  1                0  \n",
                            "2                  0                7  \n",
                            "3                  0               14  \n",
                            "4                  0               17  \n",
                            "\n",
                            "[5 rows x 22 columns]"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data_stations_clean_inferences.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Merge Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DESCARTAMOS OPCIONES"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***option 1***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#trips_data_merge = pd.merge(trips_data, data_stations_final_unlock_lock, how='left', left_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock', 'lock_date', 'lock_hour', 'longitude_lock', 'latitude_lock'], right_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock', 'lock_date', 'lock_hour', 'longitude_lock', 'latitude_lock'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***option R***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Supongamos que 'trips_data' es tu DataFrame trips_data y 'data_stations_final_unlock_lock' es el otro DataFrame.\n",
                "\n",
                "# Convertir la columna de fecha a tipo datetime\n",
                "trips_data['unlock_date'] = pd.to_datetime(trips_data['unlock_date'])\n",
                "\n",
                "# Realizar un merge en las columnas de coincidencia\n",
                "merged_data = pd.merge(trips_data, data_stations_final_unlock_lock,\n",
                "                       left_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock'],\n",
                "                       right_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock'],\n",
                "                       how='left', suffixes=('_trip', '_station'))\n",
                "\n",
                "# Identificar las filas que no tuvieron coincidencias\n",
                "no_match_mask = merged_data['name_unlock'].isnull()\n",
                "\n",
                "# Concatenar las filas sin coincidencias al DataFrame resultante\n",
                "result_data = pd.concat([merged_data[no_match_mask], merged_data[~no_match_mask].drop_duplicates()])\n",
                "\n",
                "# Imprimir el DataFrame resultante\n",
                "print(result_data.head())\n",
                "\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Opcion J (Utiliza un bucle y agrega las filas al DataFrame uno por uno) 👉 Computacionalmente no parece asumible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imprimir las primeras filas del DataFrame resultante\n",
                "print(trips_data_merge.head())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Tu código para cargar los conjuntos de datos\n",
                "# ...\n",
                "\n",
                "# Realizar merge con tipo 'left'\n",
                "trips_data_merge = pd.merge(trips_data, data_stations_final_unlock_lock, how='left', left_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock'], right_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock'])\n",
                "\n",
                "# Imprimir las primeras filas del DataFrame resultante\n",
                "print(trips_data_merge.head())\n",
                "\n",
                "# Estadísticas y tipos de datos\n",
                "print(trips_data_merge.describe())\n",
                "print(trips_data_merge.dtypes)\n",
                "\n",
                "# Contar valores nulos por columna\n",
                "print(trips_data_merge.isnull().sum())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertir la columna 'combined_datetime' de ambos DataFrames a datetime\n",
                "trips_data['combined_datetime'] = pd.to_datetime(trips_data['combined_datetime'])\n",
                "data_stations_final_unlock_lock['combined_datetime'] = pd.to_datetime(data_stations_final_unlock_lock['combined_datetime'])\n",
                "\n",
                "# Realizar un merge utilizando 'outer'\n",
                "trips_data_merge_outer = pd.merge(trips_data, data_stations_final_unlock_lock, on=['combined_datetime', 'longitude_unlock', 'latitude_unlock'], how='outer')\n",
                "\n",
                "# Restablecer el índice del DataFrame resultante\n",
                "trips_data_merge_outer.reset_index(drop=True, inplace=True)\n",
                "\n",
                "# Imprimir el DataFrame resultante\n",
                "print(trips_data_merge_outer.head())\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data_merge2 = pd.DataFrame(columns=trips_data.columns)\n",
                "\n",
                "trips_data['unlock_hour'] = pd.to_datetime(trips_data['unlock_hour'])\n",
                "data_stations_final_unlock_lock['unlock_hour'] = pd.to_datetime(data_stations_final_unlock_lock['unlock_hour'])\n",
                "\n",
                "for index, row in trips_data.iterrows():\n",
                "    # Convertir la fecha de desbloqueo a datetime\n",
                "    fecha_desbloqueo = pd.to_datetime(row['unlock_date'])\n",
                "    \n",
                "    # Filtrar las filas de 'data_stations_final_unlock_lock' que coinciden con la fecha y la hora de desbloqueo\n",
                "    filtro = (data_stations_final_unlock_lock['unlock_date'] == fecha_desbloqueo) & \\\n",
                "             (data_stations_final_unlock_lock['unlock_hour'].dt.hour == row['unlock_hour'].dt.hour) & \\\n",
                "             (data_stations_final_unlock_lock['longitude_unlock'] == row['longitude_unlock']) & \\\n",
                "             (data_stations_final_unlock_lock['latitude_unlock'] == row['latitude_unlock'])\n",
                "    \n",
                "    # Agregar la fila de 'trips_data' al nuevo DataFrame\n",
                "    trips_data_merge2 = trips_data_merge2.append(row)\n",
                "    \n",
                "    # Si existe una fila correspondiente en 'data_stations_final_unlock_lock', agregarla al nuevo DataFrame\n",
                "    if not data_stations_final_unlock_lock[filtro].empty:\n",
                "        trips_data_merge2 = trips_data_merge2.append(data_stations_final_unlock_lock[filtro].iloc[0])\n",
                "\n",
                "# Imprimir el DataFrame resultante\n",
                "trips_data_merge2.head()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "def explore_dataframe_info(dataframe):\n",
                "    # Ver las primeras filas\n",
                "    print(\"Primeras filas del DataFrame:\")\n",
                "    print(dataframe.head())\n",
                "\n",
                "    # Descripción estadística básica\n",
                "    print(\"\\nDescripción estadística:\")\n",
                "    print(dataframe.describe())\n",
                "\n",
                "    # Tipos de datos\n",
                "    print(\"\\nTipos de datos de las columnas:\")\n",
                "    print(dataframe.dtypes)\n",
                "\n",
                "    # Contar valores nulos\n",
                "    print(\"\\nCantidad de valores nulos por columna:\")\n",
                "    print(dataframe.isnull().sum())\n",
                "\n",
                "    # Explorar valores únicos en cada columna\n",
                "    print(\"\\nValores únicos en cada columna:\")\n",
                "    for column in dataframe.columns:\n",
                "        print(f\"\\nColumna: {column}\")\n",
                "        print(dataframe[column].unique())\n",
                "\n",
                "# Ejemplo de uso con uno de tus DataFrames\n",
                "explore_dataframe_info(trips_data)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def explore_dataframe_info(df):\n",
                "    \"\"\"\n",
                "    Muestra información detallada sobre un DataFrame, incluyendo descripciones estadísticas,\n",
                "    tipos de datos, y conteo de valores nulos por columna.\n",
                "\n",
                "    Parameters:\n",
                "    - df: DataFrame de pandas\n",
                "\n",
                "    Returns:\n",
                "    - None (imprime la información directamente)\n",
                "    \"\"\"\n",
                "\n",
                "    # Primeras filas del DataFrame\n",
                "    print(f\"Primeras filas del DataFrame:\\n{df.head()}\")\n",
                "\n",
                "    # Descripción estadística\n",
                "    print(\"\\nDescripción estadística:\")\n",
                "    print(df.describe())\n",
                "\n",
                "    # Tipos de datos de las columnas\n",
                "    print(\"\\nTipos de datos de las columnas:\")\n",
                "    print(df.dtypes)\n",
                "\n",
                "    # Cantidad de valores nulos por columna\n",
                "    print(\"\\nCantidad de valores nulos por columna:\")\n",
                "    print(df.isnull().sum())\n",
                "\n",
                "# Aplicar la función al DataFrame data_stations_final_unlock_lock\n",
                "explore_dataframe_info(data_stations_final_unlock_lock)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(trips_data['unlock_date'].dtype)\n",
                "print(trips_data['unlock_hour'].dtype)\n",
                "print(data_stations_final_unlock_lock['unlock_date'].dtype)\n",
                "print(data_stations_final_unlock_lock['unlock_hour'].dtype)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Asegúrate de convertir las columnas de fecha y hora a tipos de datos apropiados\n",
                "trips_data['unlock_date'] = pd.to_datetime(trips_data['unlock_date'])\n",
                "data_stations_final_unlock_lock['unlock_date'] = pd.to_datetime(data_stations_final_unlock_lock['unlock_date'])\n",
                "trips_data['unlock_hour'] = pd.to_datetime(trips_data['unlock_hour']).dt.time\n",
                "data_stations_final_unlock_lock['unlock_hour'] = pd.to_datetime(data_stations_final_unlock_lock['unlock_hour']).dt.time\n",
                "\n",
                "# Crea una nueva columna 'combined_datetime' en ambos DataFrames\n",
                "trips_data['combined_datetime'] = pd.to_datetime(trips_data['unlock_date'].astype(str) + ' ' + trips_data['unlock_hour'].astype(str))\n",
                "data_stations_final_unlock_lock['combined_datetime'] = pd.to_datetime(data_stations_final_unlock_lock['unlock_date'].astype(str) + ' ' + data_stations_final_unlock_lock['unlock_hour'].astype(str))\n",
                "\n",
                "# Realiza la fusión de los DataFrames utilizando 'merge'\n",
                "trips_data_merge2 = pd.merge(trips_data, data_stations_final_unlock_lock,\n",
                "                             left_on=['combined_datetime', 'longitude_unlock', 'latitude_unlock'],\n",
                "                             right_on=['combined_datetime', 'longitude_unlock', 'latitude_unlock'],\n",
                "                             how='left')\n",
                "\n",
                "# Elimina columnas temporales\n",
                "trips_data_merge2 = trips_data_merge2.drop(columns=['combined_datetime'])\n",
                "\n",
                "# Elimina duplicados si es necesario\n",
                "trips_data_merge2 = trips_data_merge2.drop_duplicates()\n",
                "\n",
                "# Imprime el DataFrame resultante\n",
                "print(trips_data_merge2.head())\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convertir las columnas de fecha y hora a tipo datetime en ambos DataFrames\n",
                "trips_data['unlock_hour'] = pd.to_datetime(trips_data['unlock_hour'])\n",
                "data_stations_final_unlock_lock['unlock_hour'] = pd.to_datetime(data_stations_final_unlock_lock['unlock_hour'])\n",
                "trips_data['unlock_date'] = pd.to_datetime(trips_data['unlock_date'])\n",
                "\n",
                "# Merge de los DataFrames utilizando 'merge'\n",
                "trips_data_merge2 = pd.merge(trips_data, data_stations_final_unlock_lock,\n",
                "                             left_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock'],\n",
                "                             right_on=['unlock_date', 'unlock_hour', 'longitude_unlock', 'latitude_unlock'],\n",
                "                             how='left')\n",
                "\n",
                "# Eliminar duplicados si es necesario\n",
                "trips_data_merge2 = trips_data_merge2.drop_duplicates()\n",
                "\n",
                "# Imprimir el DataFrame resultante\n",
                "print(trips_data_merge2.head())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Convertir las columnas de fecha y hora a tipo datetime\n",
                "trips_data['unlock_hour'] = pd.to_datetime(trips_data['unlock_hour'])\n",
                "data_stations_final_unlock_lock['unlock_hour'] = pd.to_datetime(data_stations_final_unlock_lock['unlock_hour'])\n",
                "trips_data['unlock_date'] = pd.to_datetime(trips_data['unlock_date'])\n",
                "\n",
                "# Crear un DataFrame vacío sin especificar columnas\n",
                "trips_data_merge2 = pd.DataFrame()\n",
                "\n",
                "for index, row in trips_data.iterrows():\n",
                "    # Convertir la fecha de desbloqueo a datetime\n",
                "    fecha_desbloqueo = pd.to_datetime(row['unlock_date'])\n",
                "    \n",
                "    # Filtrar las filas de 'data_stations_final_unlock_lock' que coinciden con la fecha y la hora de desbloqueo\n",
                "    filtro = (data_stations_final_unlock_lock['unlock_date'] == fecha_desbloqueo) & \\\n",
                "             (data_stations_final_unlock_lock['unlock_hour'].dt.hour == row['unlock_hour'].hour) & \\\n",
                "             (data_stations_final_unlock_lock['longitude_unlock'] == row['longitude_unlock']) & \\\n",
                "             (data_stations_final_unlock_lock['latitude_unlock'] == row['latitude_unlock'])\n",
                "    \n",
                "    # Agregar la fila de 'trips_data' al nuevo DataFrame\n",
                "    trips_data_merge2 = trips_data_merge2.append(row)\n",
                "    \n",
                "    # Si existe una fila correspondiente en 'data_stations_final_unlock_lock', agregarla al nuevo DataFrame\n",
                "    if not data_stations_final_unlock_lock[filtro].empty:\n",
                "        trips_data_merge2 = trips_data_merge2.append(data_stations_final_unlock_lock[filtro].iloc[0])\n",
                "\n",
                "# Eliminar duplicados si es necesario\n",
                "trips_data_merge2 = trips_data_merge2.drop_duplicates()\n",
                "\n",
                "# Imprimir el DataFrame resultante\n",
                "print(trips_data_merge2.head())\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trips_data['lock_hour'] = pd.to_datetime(trips_data['lock_hour'])\n",
                "data_stations_final_unlock_lock['lock_hour'] = pd.to_datetime(data_stations_final_unlock_lock['lock_hour'])\n",
                "\n",
                "for index, row in trips_data.iterrows():\n",
                "    # Convertir la fecha de desbloqueo a datetime\n",
                "    fecha_desbloqueo_l = pd.to_datetime(row['lock_date'])\n",
                "    \n",
                "    # Filtrar las filas de 'data_stations_final_unlock_lock' que coinciden con la fecha y la hora de desbloqueo\n",
                "    filtro = (data_stations_final_unlock_lock['lock_date'] == fecha_desbloqueo_l) & \\\n",
                "             (data_stations_final_unlock_lock['lock_hour'].dt.hour == row['lock_hour'].dt.hour) & \\\n",
                "             (data_stations_final_unlock_lock['longitude_lock'] == row['longitude_lock']) & \\\n",
                "             (data_stations_final_unlock_lock['latitude_lock'] == row['latitude_lock'])\n",
                "    \n",
                "    # Agregar la fila de 'trips_data' al nuevo DataFrame\n",
                "    trips_data_merge2 = trips_data_merge2.append(row)\n",
                "    \n",
                "    # Si existe una fila correspondiente en 'data_stations_final_unlock_lock', agregarla al nuevo DataFrame\n",
                "    if not data_stations_final_unlock_lock[filtro].empty:\n",
                "        trips_data_merge2 = trips_data_merge2.append(data_stations_final_unlock_lock[filtro].iloc[0])\n",
                "\n",
                "# Imprimir el DataFrame resultante\n",
                "trips_data_merge2.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***Save the clean data***"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# trips_data_merge.to_csv('../data/processed/clean_data_trips_stations.csv', index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
